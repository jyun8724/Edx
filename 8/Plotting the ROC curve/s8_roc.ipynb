{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import roc_auc_score\n",
                "from sklearn.metrics import confusion_matrix\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eage\u003c/th\u003e\n      \u003cth\u003esex\u003c/th\u003e\n      \u003cth\u003ecough\u003c/th\u003e\n      \u003cth\u003efever\u003c/th\u003e\n      \u003cth\u003echills\u003c/th\u003e\n      \u003cth\u003esore_throat\u003c/th\u003e\n      \u003cth\u003eheadache\u003c/th\u003e\n      \u003cth\u003efatigue\u003c/th\u003e\n      \u003cth\u003eurgency\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e30\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e47\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e49\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e50\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e59\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   age  sex  cough  fever  chills  sore_throat  headache  fatigue  urgency\n0   30    1      0      0       0            0         0        0        0\n1   47    1      0      0       0            0         0        0        0\n2   49    1      0      0       0            0         0        0        0\n3   50    0      0      0       0            0         0        0        0\n4   59    0      0      1       0            0         0        0        0"
                    },
                    "execution_count": 97,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Read the datafile \"covid_train.csv\"\n",
                "train_data = pd.read_csv('covid_train.csv')\n",
                "# Take a quick look at the dataframe\n",
                "train_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eage\u003c/th\u003e\n      \u003cth\u003esex\u003c/th\u003e\n      \u003cth\u003ecough\u003c/th\u003e\n      \u003cth\u003efever\u003c/th\u003e\n      \u003cth\u003echills\u003c/th\u003e\n      \u003cth\u003esore_throat\u003c/th\u003e\n      \u003cth\u003eheadache\u003c/th\u003e\n      \u003cth\u003efatigue\u003c/th\u003e\n      \u003cth\u003eurgency\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e47\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e42\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e21\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e41\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e43\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   age  sex  cough  fever  chills  sore_throat  headache  fatigue  urgency\n0   47    0      0      0       0            0         0        0        0\n1   42    0      0      1       0            0         0        0        1\n2   21    1      0      0       0            0         0        0        1\n3   41    1      0      0       0            0         0        0        1\n4   43    1      0      1       0            0         0        0        0"
                    },
                    "execution_count": 98,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Read the datafile \"covid_test.csv\"\n",
                "test_data = pd.read_csv('covid_test.csv')\n",
                "# Take a quick look at the dataframe\n",
                "test_data.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Separate the predictors from the response variables in both train and test sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_Xy) ###\n",
                "\n",
                "# Get the train predictors\n",
                "X_train = train_data.drop(columns=['urgency'])\n",
                "\n",
                "# Get the train response variable\n",
                "y_train = train_data['urgency']\n",
                "\n",
                "# Get the test predictors\n",
                "X_test = test_data.drop(columns=['urgency'])\n",
                "\n",
                "# Get the test response variable\n",
                "y_test = test_data['urgency']"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We want to compare two different classifiers: kNN and logistic regression.\n",
                "\n",
                "First, let's create a fit a kNN model and get's its predicted probabilities for the positive class on the test data.\n",
                "\n",
                "**Hint:** Remember that the `predict_proba` method returns probabilities for all classes. We only want the probabilities for the positive class (i.e., $y = 1$). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_kNN) ###\n",
                "\n",
                "# Define a kNN classification model with k = 7\n",
                "knn = KNeighborsClassifier(n_neighbors=7)\n",
                "\n",
                "# Fit the above model on the train data\n",
                "knn.fit(X_train, y_train)\n",
                "\n",
                "# Predict probabilities for the positive class on the test data using the kNN model\n",
                "y_pred_knn = knn.predict_proba(X_test)[:, 1]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's do the same for a logistic regression model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_logreg) ###\n",
                "\n",
                "# Define a Logistic Regression model with max_iter as 10000, C as 0.1, and a random_state of 42\n",
                "logreg = LogisticRegression(max_iter=10000, C=0.1, random_state=42)\n",
                "\n",
                "# Fit the Logistic Regression model on the train data\n",
                "logreg.fit(X_train, y_train)\n",
                "\n",
                "# Predict probabilities for the positive class on the test data using the logistic regression model\n",
                "y_pred_logreg = logreg.predict_proba(X_test)[:, 1]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### ROC Curve Review\n",
                "\n",
                "The Bayes threshold of a binary classifier is the value for which all predicted probabilities greater than or equal to that value are labeled as the positive class. For example, a classifier with a Bayes threshold of 0.6 will classify all observations with a predicted probability, $p \\geq 0.6$, as the positive class (1) and all observations with a predicted probability, $p \u003c 0.6$, as the negative class (0).\n",
                "\n",
                "The ROC curve shows us a model's false positive  and true positive rates across different settings of the Bayes Threshold. \n",
                "\n",
                "Recall that:\n",
                "$$\\text{False Positive Rate} = \\frac{FP}{TN + FP}$$\n",
                "$$\\text{True Positive Rate} = \\frac{TP}{TP + FN}$$\n",
                "\n",
                "We will compute the false positve rate (FPR) and true positive rate (TPR) for a range of thresholds and use these values to plot ROC curves for both the kNN and the logistic regression models."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Thresholds\n",
                "\n",
                "First, we need to generate a range of thresholds to use for turning our models' probability predictions into class labels. One naive approach might be to simply create a list of evenly spaced values between 0 and 1 and use these for both models. But this is not ideal. Consider the fact that some threshold changes will not actually affect the model's classification labels.\n",
                "\n",
                "Example: if a model predicts probabilities `[0.54, 0.77, 0.79]` for 3 observations, all thresholds in the half-open interval (0.54, 0.77] will produce the exact same class labels: `[0, 1, 1]`\n",
                "\n",
                "Another issue is that we may fail to see all changes in the class labels if our set of thresholds is not sufficiently granular. Consider the example of the 3 predicted probabilities above once more. If we use thresholds in steps of 0.05 (0, 0.05, 0.1, ..., 0.95, 1) we would only ever see class label predictions of [0, 1, 1] and [0, 0, 0]. We would miss an important threshold like 0.78 which would produce the class lables [0, 0, 1], potentially giving us a different TPR and FPR.\n",
                "\n",
                "Our approach will be to evaluate just those thresholds that result in different class label predictions. And these precise thresholds will depend on our model.\n",
                "\n",
                "Complete the `get_thresholds` function which takes a model's predicted probabilities on the test set and returns an array of thresholds to be considered."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_thresholds(y_pred_proba):\n",
                "    # We only need to consider unique predicted probabilities\n",
                "    unique_probas = np.unique(y_pred_proba)\n",
                "    # Sort unique probabilities in descending order\n",
                "    unique_probas_sorted = np.sort(unique_probas)[::-1]\n",
                "   \n",
                "    # We'll also add some additional thresholds to our set\n",
                "    # This ensures our ROC curves reach the corners of the plot, (0,0) and (1,1)\n",
                "    \n",
                "    # Insert 1.1 at the beginning of the threshold array\n",
                "    # 1.1 may seem like an odd threshold, but a value greater than 1\n",
                "    # is required if we want the ROC curve to reach the lower left corner\n",
                "    # (0 fpr, 0 tpr) considering one of our models produces probability predictions of 1\n",
                "    thresholds = np.insert(unique_probas_sorted, 0, 1.1)\n",
                "    # Append 0 to the end of the thresholds\n",
                "    thresholds = np.append(thresholds, 0)\n",
                "    return thresholds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_thresholds) ###\n",
                "\n",
                "knn_thresholds = get_thresholds(y_pred_knn)\n",
                "\n",
                "logreg_thresholds = get_thresholds(y_pred_logreg)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### FPR \u0026 TPR\n",
                "\n",
                "Now we can use the true $y$ class label and the predicted probabilities to determine the the fpr and tpr on the test data for a specific threshold. Complete the `get_fpr` and `get_tpr` functions below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_fpr) ###\n",
                "\n",
                "def get_fpr(y_true, y_pred_proba, threshold):\n",
                "    # your code here\n",
                "    y_pred = (y_pred_proba \u003e= threshold).astype(int)\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "    tn = cm[0, 0]\n",
                "    fp = cm[0, 1]\n",
                "\n",
                "    if (tn + fp) \u003e 0:\n",
                "        fpr = fp / (tn + fp)\n",
                "    else:\n",
                "        fpr = 0\n",
                "    return fpr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_tpr) ###\n",
                "\n",
                "def get_tpr(y_true, y_pred_proba, threshold):\n",
                "    # your code here\n",
                "    y_pred = (y_pred_proba \u003e= threshold).astype(int)\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "    tp = cm[1, 1]\n",
                "    fn = cm[1, 0]\n",
                "    if (tp + fn) \u003e 0:\n",
                "        tpr = tp / (tp + fn)\n",
                "    else:\n",
                "        tpr = 0\n",
                "    return tpr"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Use these functions to get the FPR and TPR for both models using each threshold for that model. These calculations can be done in a loop, but you should also try doing them with Python list comprehensions as well."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_fpr_tpr) ###\n",
                "\n",
                "# FPR for the kNN at each of its thresholds\n",
                "knn_fpr = [get_fpr(y_test, y_pred_knn, threshold) for threshold in knn_thresholds]\n",
                "# TPR for the kNN at each of its thresholds\n",
                "knn_tpr = [get_tpr(y_test, y_pred_knn, threshold) for threshold in knn_thresholds]\n",
                "# TPR for the logistic model at each of its thresholds\n",
                "logreg_tpr = [get_tpr(y_test, y_pred_logreg, threshold) for threshold in logreg_thresholds]\n",
                "# FPR for the logistic model at each of its thresholds\n",
                "logreg_fpr = [get_fpr(y_test, y_pred_logreg, threshold) for threshold in logreg_thresholds]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Area Under the Curve\n",
                "\n",
                "The AUC gives us an idea as to how well our model does across *all* thresholds.\n",
                "\n",
                "For our final calculations, use each model's predicted probabilities to compute its test AUC with the help of SKLearn's `roc_auc_score` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[106], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### edTest(test_fpr_tpr) ###\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# FPR for the kNN at each of its thresholds\u001b[39;00m\n\u001b[0;32m----\u003e 4\u001b[0m knn_fpr \u001b[38;5;241m=\u001b[39m [\u001b[43mget_fpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_knn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m knn_thresholds]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# TPR for the kNN at each of its thresholds\u001b[39;00m\n\u001b[1;32m      6\u001b[0m knn_tpr \u001b[38;5;241m=\u001b[39m [get_tpr(y_test, y_pred_knn, threshold) \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m knn_thresholds]\n",
                        "Cell \u001b[0;32mIn[104], line 6\u001b[0m, in \u001b[0;36mget_fpr\u001b[0;34m(y_true, y_pred_proba, threshold)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fpr\u001b[39m(y_true, y_pred_proba, threshold):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# your code here\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (y_pred_proba \u001b[38;5;241m\u003e\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m----\u003e 6\u001b[0m     cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     tn \u001b[38;5;241m=\u001b[39m cm[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cm[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
                        "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.\u003clocals\u003e.decorator.\u003clocals\u003e.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--\u003e 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
                        "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    248\u001b[0m     {\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    (np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--\u003e 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
                        "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m\u003e\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--\u003e 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    114\u001b[0m             type_true, type_pred\n\u001b[1;32m    115\u001b[0m         )\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type =\u003e The set is no more needed\u001b[39;00m\n\u001b[1;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
                        "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
                    ]
                }
            ],
            "source": [
                "### edTest(test_auc) ###\n",
                "\n",
                "# Compute the ROC AUC score of the Logistic model\n",
                "knn_auc = roc_auc_score(y_test, y_pred_knn)\n",
                "\n",
                "# Compute the ROC AUC score of the kNN model\n",
                "logreg_auc = roc_auc_score(y_test, y_pred_logreg)\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You're ready to visualize your results!\n",
                "\n",
                "Most of the code is provided. You just need to fill in the values to be plotted for the two models' ROC curves.\n",
                "\n",
                "Remember that the convention is that false positive rate is on the $x$-axis and true positive rate is on the $y$-axis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_plot) ###\n",
                "\n",
                "# Area under curve - Logistic Regression \u0026 kNN\n",
                "fig, ax = plt.subplots(figsize = (14,8))\n",
                "\n",
                "# Plot KNN Regression ROC Curve\n",
                "ax.plot(knn_fpr,\n",
                "        knn_tpr,\n",
                "        label=f'KNN (area = {knn_auc:.2f})',\n",
                "        color='g',\n",
                "        lw=3)\n",
                "\n",
                "# Plot Logistic Regression ROC Curve\n",
                "ax.plot(logreg_fpr,\n",
                "        logreg_tpr,\n",
                "        label=f'Logistic Regression (area = {logreg_auc:.2f})',\n",
                "        color = 'purple',\n",
                "        lw=3)\n",
                "\n",
                "# Threshold annotations\n",
                "label_kwargs = {}\n",
                "label_kwargs['bbox'] = dict(\n",
                "    boxstyle='round, pad=0.3', color='lightgray', alpha=0.6\n",
                ")\n",
                "eps = 0.02 # offset\n",
                "for i in range(0, len(logreg_fpr),15):\n",
                "    threshold = str(np.round(logreg_thresholds[i], 2))\n",
                "    ax.annotate(threshold, (logreg_fpr[i], logreg_tpr[i]-eps), fontsize=12, color='purple', **label_kwargs)\n",
                "\n",
                "for i in range(0, len(knn_fpr)-1):\n",
                "    threshold = str(np.round(knn_thresholds[i], 2))\n",
                "    ax.annotate(threshold, (knn_fpr[i], knn_tpr[i]+eps), fontsize=12, color='green', **label_kwargs)\n",
                "\n",
                "# Plot diagonal line representing a random classifier\n",
                "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
                "\n",
                "# Scenario 1 - Brazil\n",
                "ax.fill_between([0,0.5],[0.5,0], color = 'red', alpha = 0.4, label='Scenario 1 - Brazil');\n",
                "\n",
                "# Scenario 2 - Germany\n",
                "ax.axhspan(0.8, 0.9, facecolor='y', alpha=0.4, label = 'Scenario 2 - Germany');\n",
                "\n",
                "# Scenario 3 - India\n",
                "ax.fill_between([0,1],[1,0],[0.5,-0.5], alpha = 0.4, color = 'blue', label = 'Scenario 3 - India');\n",
                "\n",
                "ax.set_xlim([0.0, 1.0]);\n",
                "ax.set_ylim([0.0, 1.05]);\n",
                "ax.set_xlabel('False Positive Rate', fontsize=20)\n",
                "ax.set_ylabel('True Positive Rate', fontsize=20)\n",
                "ax.set_title('Receiver Operating Characteristic', fontsize=20)\n",
                "ax.legend(loc=\"lower right\", fontsize=15)\n",
                "plt.show()"
            ]
        }
    ]
}
